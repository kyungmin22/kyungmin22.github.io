<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>수어 동작을 인식시켜보세요.</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <style>
        /* (이하 동일) */
    </style>
</head>
<body>
    <!-- (이하 동일) -->
    <div id="label-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
    <script type="text/javascript">
        // (이하 동일)

        async function predict() {
            const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
            const prediction = await model.predict(posenetOutput);

            let maxIndex = 0;
            for (let i = 1; i < maxPredictions; i++) {
                if (prediction[i].probability > prediction[maxIndex].probability) {
                    maxIndex = i;
                }
            }

            const classPrediction = prediction[maxIndex].className;
            labelContainer.innerHTML = classPrediction;

            // 추가: 특정 동작이 감지되면 음성 출력
            if (classPrediction === 'YOUR_DETECTED_GESTURE') {
                speak('특정 동작이 감지되었습니다. 음성 출력!');
            }

            drawPose(pose);
        }

        // 추가: 음성 출력 함수
        function speak(message) {
            // 실제로는 브라우저에서 지원하는 Web Speech API나 다른 음성 합성 API를 사용해야 합니다.
            // 여기에서는 간단히 console.log로 대체되어 있습니다.
            console.log('Voice Output:', message);
        }

        // (이하 동일)
    </script>
</body>
</html>
