<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>수어 동작을 인식시켜보세요.</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
        }

        .header {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 100%;
        }

        .header button {
            font-size: 24px;
            margin-right: 20px;
        }

        

        #label-container {
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div class="header">
        <button onclick="goBack()">
            <i class="fas fa-home"></i>
        </button>
        <h1>수어 동작을 인식시켜보세요.</h1>
    </div>

    <button type="button" onclick="init()">인식하기</button>
    <div><canvas id="canvas"></canvas></div>
    <div id="label-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
    <script type="text/javascript">
        const URL = "./my_model/";
        let model, webcam, ctx, labelContainer, maxPredictions;

        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            model = await tmPose.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            const size = 200;
            const flip = true;
            webcam = new tmPose.Webcam(size, size, flip);
            await webcam.setup();
            await webcam.play();
            window.requestAnimationFrame(loop);

            const canvas = document.getElementById("canvas");
            canvas.width = size;
            canvas.height = size;
            ctx = canvas.getContext("2d");
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }
        }

        async function loop(timestamp) {
            webcam.update();
            await predict();
            window.requestAnimationFrame(loop);
        }

        async function predict() {
            const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
            const prediction = await model.predict(posenetOutput);

            let maxIndex = 0;
            for (let i = 1; i < maxPredictions; i++) {
                if (prediction[i].probability > prediction[maxIndex].probability) {
                    maxIndex = i;
                }
            }

            const classPrediction = prediction[maxIndex].className;
            labelContainer.innerHTML = classPrediction;

            drawPose(pose);
        }

        function drawPose(pose) {
            if (webcam.canvas) {
                ctx.drawImage(webcam.canvas, 0, 0);
                if (pose) {
                    const minPartConfidence = 0.5;
                    tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
                    tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
                }
            }
        }

        function goBack() {
            window.history.back();
        }
    </script>
</body>
</html> 